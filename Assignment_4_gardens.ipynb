{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bec8f5c-90cb-4936-a161-b1f1c53ed2df",
   "metadata": {},
   "source": [
    "# Extracting and Transforming Metadata\n",
    "\n",
    "This notebook illustrates a second step in the \"transform\" process.\n",
    "Although there are many possible data transformation pathways, this demonstration\n",
    "illustrates a process that converts metadata into an open, non-proprietary,\n",
    "text-based format: the CSV file.\n",
    "\n",
    "As throughout, the general process here follows the generalized \"Extract - Transform - Load\" process, which is frequently the abstract model for pulling data from one system, transporting, cleaning, and outputting to another system, which remains the overall workflow.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "After completing the assignment associated with this notebook, you should: \n",
    "\n",
    "* Use programming (Python) to work with data supplied by an API in JSON format to manage and transform useful parts of that data into a CSV format.\n",
    "* Create ingest-ready collection metadata that conforms to Dublin Core and other digital collection metadata standards, which can be used to load content into another site (in this case, a new collection platform, like Omeka S or CollectionBuilder).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The main steps outlined in this notebook are as follows:\n",
    "\n",
    "* **Transform the metadata.** This step assumes you have already developed a plan for transforming your data, which is your Metadata Application Profile, or MAP.\n",
    "  1. Develop your transformation script with a small subset of the metadata. In this case, one record.\n",
    "  1. Transform the data you've gathered in JSON into a CSV file according to the metadata crosswalk you've developed. The goal in this step is to create a CSV that we can use to import items into your Omeka site (using the CSV Import module). Note that the code outlined here suggests how all of these data elements may be extracted and transformed, but it does not necessarily output all of the elements that you will need to complete your assignment. In other words, there is still work to do to complete this code, but you are welcome to adopt or reuse the code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a281bf-4fb1-4bb2-b01f-d4f1c523e905",
   "metadata": {},
   "source": [
    "# Get collection list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd81df05-072c-47cd-b4dc-b3abdbaa8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# for working with local files\n",
    "import glob\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45a3bb-b954-44d9-9446-97a049c9b974",
   "metadata": {},
   "source": [
    "# Transformation Part 1: Testing\n",
    "\n",
    "At a high level, the transformation step involves the creation of code or another implementation workflow, which will search the item metadata files downloaded previously, extract the target fields identified in the MAP, then write that information to a CSV for ingest or loading into a new presentation platform.\n",
    "\n",
    "First, develop a search pattern for identifying the desired JSON files. Here, you create a list of the files that you want to transform, called `list_of_item_metadata_files`. \n",
    "\n",
    "**Reminder:** This step builds on your terminal skills! (And builds on your understanding of regular expressions and shell navigation. Note, however, these are technically file path expansions, not actual regular expressions. The general idea of creating a pattern and asking the computer to respond with a list of results that meet your criteria, is similar.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a899bee6-bed9-4240-85ed-1c946110f2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kenda\\Desktop\\si676-networked-information-services\\Collection Project\n"
     ]
    }
   ],
   "source": [
    "current_loc = os.getcwd()\n",
    "\n",
    "print(current_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e195bef-fe55-47e7-a1af-5ecf0c0f324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-metadata-gardens\n"
     ]
    }
   ],
   "source": [
    "metadata_file_path = os.path.join('item-metadata-gardens')\n",
    "\n",
    "print(metadata_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c6363a",
   "metadata": {},
   "source": [
    "The next cell uses the `glob` library, which supports the use of file path expanders\n",
    "to look for patterns in file paths. In this case, the previous item metadata exraction\n",
    "wrote files that had the pattern `item_metadata-[item-identifier].json`. \n",
    "So, to match any pattern for the `item-identifier` section, `glob` allows\n",
    "the use of the `*` (asterisk) character to match any pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff4a730-4208-4e63-8531-4b6da696ec0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-metadata-gardens\\item_metadata-afc1999008.afc1999008_crf_mhc05407.json\n",
      "item-metadata-gardens\\item_metadata-cph.3a25266.json\n",
      "item-metadata-gardens\\item_metadata-cph.3c30923.json\n",
      "item-metadata-gardens\\item_metadata-cph.3f05737.json\n",
      "item-metadata-gardens\\item_metadata-cph.3g05158.json\n",
      "item-metadata-gardens\\item_metadata-ds.03659.json\n",
      "item-metadata-gardens\\item_metadata-ds.13761.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8a19113.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8b14071.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8b14514.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8c19781.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8d21091.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8d31670.json\n",
      "item-metadata-gardens\\item_metadata-ggbain.01389.json\n",
      "item-metadata-gardens\\item_metadata-hhh.ca1376.photos.json\n",
      "item-metadata-gardens\\item_metadata-hhh.ma1202.sheet.json\n",
      "item-metadata-gardens\\item_metadata-highsm.13145.json\n",
      "item-metadata-gardens\\item_metadata-highsm.16140.json\n",
      "item-metadata-gardens\\item_metadata-highsm.17208.json\n",
      "item-metadata-gardens\\item_metadata-highsm.18085.json\n",
      "item-metadata-gardens\\item_metadata-highsm.51078.json\n",
      "item-metadata-gardens\\item_metadata-highsm.58260.json\n",
      "item-metadata-gardens\\item_metadata-mrg.00279.json\n",
      "item-metadata-gardens\\item_metadata-npcc.20263.json\n",
      "item-metadata-gardens\\item_metadata-pga.14314.json\n",
      "item-metadata-gardens\\item_metadata-ppmsc.05210.json\n",
      "item-metadata-gardens\\item_metadata-ppmsc.08589.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16143.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16211.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16216.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16226.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16693.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16752.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.38775.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.67920.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.83823.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.83865.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s00324.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s04657.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s06147.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s07844.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s08717.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s26666.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s30968.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s31930.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s38444.json\n",
      "item-metadata-gardens\\item_metadata-thc.5a50527.json\n",
      "item-metadata-gardens\\item_metadata-wtc.4a03254.json\n",
      "found 48\n"
     ]
    }
   ],
   "source": [
    "file_count = 0\n",
    "\n",
    "for file in glob.glob('item-metadata-gardens/item_metadata-*.json'):\n",
    "    file_count += 1\n",
    "    print(file)\n",
    "\n",
    "print('found',file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8178914-945e-4bc9-a890-b717db15af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_item_metadata_files = list()\n",
    "for file in glob.glob('item-metadata-gardens/item_metadata-*.json'):\n",
    "    list_of_item_metadata_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dded9141-1613-48db-a74c-ddafd86eb247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_item_metadata_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bdb38fc-23d5-4b1d-8250-478f21deff56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-metadata-gardens\\item_metadata-afc1999008.afc1999008_crf_mhc05407.json\n",
      "item-metadata-gardens\\item_metadata-cph.3a25266.json\n",
      "item-metadata-gardens\\item_metadata-cph.3c30923.json\n",
      "item-metadata-gardens\\item_metadata-cph.3f05737.json\n",
      "item-metadata-gardens\\item_metadata-cph.3g05158.json\n",
      "item-metadata-gardens\\item_metadata-ds.03659.json\n",
      "item-metadata-gardens\\item_metadata-ds.13761.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8a19113.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8b14071.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8b14514.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8c19781.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8d21091.json\n",
      "item-metadata-gardens\\item_metadata-fsa.8d31670.json\n",
      "item-metadata-gardens\\item_metadata-ggbain.01389.json\n",
      "item-metadata-gardens\\item_metadata-hhh.ca1376.photos.json\n",
      "item-metadata-gardens\\item_metadata-hhh.ma1202.sheet.json\n",
      "item-metadata-gardens\\item_metadata-highsm.13145.json\n",
      "item-metadata-gardens\\item_metadata-highsm.16140.json\n",
      "item-metadata-gardens\\item_metadata-highsm.17208.json\n",
      "item-metadata-gardens\\item_metadata-highsm.18085.json\n",
      "item-metadata-gardens\\item_metadata-highsm.51078.json\n",
      "item-metadata-gardens\\item_metadata-highsm.58260.json\n",
      "item-metadata-gardens\\item_metadata-mrg.00279.json\n",
      "item-metadata-gardens\\item_metadata-npcc.20263.json\n",
      "item-metadata-gardens\\item_metadata-pga.14314.json\n",
      "item-metadata-gardens\\item_metadata-ppmsc.05210.json\n",
      "item-metadata-gardens\\item_metadata-ppmsc.08589.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16143.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16211.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16216.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16226.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16693.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.16752.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.38775.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.67920.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.83823.json\n",
      "item-metadata-gardens\\item_metadata-ppmsca.83865.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s00324.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s04657.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s06147.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s07844.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s08717.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s26666.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s30968.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s31930.json\n",
      "item-metadata-gardens\\item_metadata-stereo.1s38444.json\n",
      "item-metadata-gardens\\item_metadata-thc.5a50527.json\n",
      "item-metadata-gardens\\item_metadata-wtc.4a03254.json\n"
     ]
    }
   ],
   "source": [
    "# quick duplicate check\n",
    "list_of_item_metadata_files.sort()\n",
    "\n",
    "for file in list_of_item_metadata_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f634f77",
   "metadata": {},
   "source": [
    "To develop your data transformation and metadata profile, \n",
    "first you need to explore the information that you have about each item. \n",
    "To do this, explore one item to understand how the information is structured.\n",
    "How do you open the json? How is it structured? Where is the information you want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b96909e-2cce-4ca6-95b9-7d1c03c74c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: item-metadata-gardens\\item_metadata-afc1999008.afc1999008_crf_mhc05407.json \n",
      "\n",
      "_version_ : 1728618448837148672\n",
      "access_restricted : False\n",
      "aka : ['http://www.loc.gov/item/cmns001121/', 'https://hdl.loc.gov/loc.afc/afccmns.mhc05407', 'http://www.loc.gov/resource/afc1999008.afc1999008_crf_mhc05407/', 'http://www.loc.gov/item/afc1999008.afc1999008_crf_mhc05407/']\n",
      "call_number : ['AFC 1999/008: CRF-MH-C054-07']\n",
      "campaigns : []\n",
      "contributor_names : ['Jarrell, Bob (Depicted)', 'Hufford, Mary, 1952- (Photographer)']\n",
      "contributors : [{'hufford, mary': 'https://www.loc.gov/search/?fa=contributor:hufford,+mary&fo=json'}, {'jarrell, bob': 'https://www.loc.gov/search/?fa=contributor:jarrell,+bob&fo=json'}]\n",
      "created_published : ['June 28, 1996']\n",
      "date : 1996-06-28\n",
      "dates : [{'1996-06-28': 'https://www.loc.gov/search/?dates=1996-06-28/1996-06-28&fo=json'}]\n",
      "digital_id : ['http://hdl.loc.gov/loc.afc/afccmns.mhc05407']\n",
      "digitized : True\n",
      "display_offsite : True\n",
      "extract_timestamp : 2021-02-23T13:11:31.639Z\n",
      "extract_urls : ['http://c2vlpdmtool01.loc.gov/data-management-tool/export_group_xml/cmns/cmns001121.xml#cmns']\n",
      "format : [{'photo, print, drawing': 'https://www.loc.gov/search/?fa=original_format:photo,+print,+drawing&fo=json'}]\n",
      "genre : ['Photographs', 'Ethnography']\n",
      "group : ['cmns', 'tending-the-commons']\n",
      "hassegments : False\n",
      "id : http://www.loc.gov/item/cmns001121/\n",
      "image_url : ['https://tile.loc.gov/image-services/iiif/service:afc:afc1999008:afc1999008_crf_mhc05407/full/pct:12.5/0/default.jpg', 'https://tile.loc.gov/image-services/iiif/service:afc:afc1999008:afc1999008_crf_mhc05407/full/pct:12.5/0/default.jpg#h=347&w=512', 'https://tile.loc.gov/image-services/iiif/service:afc:afc1999008:afc1999008_crf_mhc05407/full/pct:25/0/default.jpg#h=694&w=1024', 'https://tile.loc.gov/image-services/iiif/service:afc:afc1999008:afc1999008_crf_mhc05407/full/pct:50/0/default.jpg#h=1388&w=2048', 'https://tile.loc.gov/image-services/iiif/service:afc:afc1999008:afc1999008_crf_mhc05407/full/pct:100/0/default.jpg#h=2776&w=4096']\n",
      "index : 1\n",
      "item : {'call_number': ['AFC 1999/008: CRF-MH-C054-07'], 'contributors': ['Jarrell, Bob (Depicted)', 'Hufford, Mary, 1952- (Photographer)'], 'created_published': ['June 28, 1996'], 'date': '19960628', 'digital_id': ['http://hdl.loc.gov/loc.afc/afccmns.mhc05407'], 'format': 'still image', 'genre': ['Photographs', 'Ethnography'], 'language': ['eng'], 'location': ['West Virginia -- Raleigh County -- Sundial'], 'medium': ['35 mm Color Slide'], 'notes': [\"Bob Jarrell is Randy Sprouse's neighbor.\"], 'repository': 'American Folklife Center', 'rights': 'No known restrictions on use or reproduction.', 'source_collection': 'Coal River Folklife Collection (AFC 1999/008)', 'subjects': ['Gardens', 'Plow and plant gardens', 'Summer', 'June', 'Photographs', 'Ethnography', 'West Virginia -- Raleigh County -- Sundial'], 'title': \"Bob Jarrell's vegetable garden\"}\n",
      "language : ['english']\n",
      "languages : [{'english': 'https://www.loc.gov/search/?fa=language:english&fo=json'}]\n",
      "location : ['west virginia', 'sundial', 'raleigh county']\n",
      "locations : [{'raleigh county': 'https://www.loc.gov/search/?fa=location:raleigh+county&fo=json'}, {'sundial': 'https://www.loc.gov/search/?fa=location:sundial&fo=json'}, {'west virginia': 'https://www.loc.gov/search/?fa=location:west+virginia&fo=json'}]\n",
      "medium : ['35 mm Color Slide']\n",
      "mime_type : ['image/tiff', 'image/jpeg', 'image/jp2']\n",
      "notes : [\"Bob Jarrell is Randy Sprouse's neighbor.\"]\n",
      "online_format : ['image']\n",
      "original_format : ['photo, print, drawing']\n",
      "other_formats : []\n",
      "partof : [{'count': 1979, 'title': 'coal river folklife collection', 'url': 'https://www.loc.gov/search/?fa=partof:coal+river+folklife+collection&fo=json'}, {'count': 2017, 'title': 'tending the commons: folklife and landscape in southern west virginia', 'url': 'https://www.loc.gov/collections/folklife-and-landscape-in-southern-west-virginia/?fo=json'}, {'count': 176657, 'title': 'american folklife center', 'url': 'https://www.loc.gov/search/?fa=partof:american+folklife+center&fo=json'}, {'count': 437343, 'title': 'american memory', 'url': 'https://www.loc.gov/search/?fa=partof:american+memory&fo=json'}]\n",
      "repository : ['American Folklife Center']\n",
      "resources : [{'files': 1, 'image': 'https://tile.loc.gov/image-services/iiif/service:afc:afc1999008:afc1999008_crf_mhc05407/full/pct:12.5/0/default.jpg', 'url': 'https://www.loc.gov/resource/afc1999008.afc1999008_crf_mhc05407/'}]\n",
      "rights : ['<p>The Library of Congress is not aware of any U.S. copyright protection (see Title 17, U.S.C.) or any other restrictions in the material in this collection, except as noted below. Users should keep in mind that the Library of Congress is providing access to these materials strictly for educational and research purposes. The written permission of the copyright owners and/or other holders of rights (such as publicity and/or privacy rights) is required for distribution, reproduction, or other use of protected items beyond that allowed by fair use or other statutory exemptions. Responsibility for making an independent legal assessment of an item and securing any necessary permissions ultimately rests with persons desiring to use the item. See our <a href=\"/legal/\">Legal Notices</a> and <a href=\"/legal/#privacy_publicity\">Privacy and Publicity Rights</a> for additional information and restrictions. </p>\\n<p>The American  Folklife  Center and the professional fieldworkers who carry out these projects feel a strong ethical responsibility to the people they have visited and who have consented to have their lives documented for the historical record. The Center asks that researchers approach the materials in this collection with respect for the culture and sensibilities of the people whose lives, ideas, and creativity are documented here. Researchers are also reminded that <a href=\"/legal/#privacy_publicity\">privacy and publicity</a> rights may pertain to certain uses of this material.</p>\\n<p>Copy photographs of numerous historical still photographs owned by Woody Boggs and Rick Bradford were made and are reproduced here with permission of the owners.</p>\\n<p>Researchers or others who would like to make further use of these collection materials should contact the <a href=\"//www.loc.gov/folklife/address.html\">Folklife Reading Room</a> for assistance. </p>\\n<h2>Credit line</h2>\\n<p>Coal River Folklife Project collection (AFC 1999/008), American Folklife Center,  Library of Congress</p>\\n']\n",
      "score : 16.904474\n",
      "shard : 01\n",
      "shelf_id : AFC 1999/008: CRF-MH-C054-07\n",
      "source_collection : Coal River Folklife Collection (AFC 1999/008)\n",
      "subject : ['photographs', 'ethnography', 'plow and plant gardens', 'june', 'gardens', 'summer']\n",
      "subject_headings : ['Gardens', 'Plow and plant gardens', 'Summer', 'June', 'Photographs', 'Ethnography', 'West Virginia -- Raleigh County -- Sundial']\n",
      "subjects : [{'ethnography': 'https://www.loc.gov/search/?fa=subject:ethnography&fo=json'}, {'gardens': 'https://www.loc.gov/search/?fa=subject:gardens&fo=json'}, {'june': 'https://www.loc.gov/search/?fa=subject:june&fo=json'}, {'photographs': 'https://www.loc.gov/search/?fa=subject:photographs&fo=json'}, {'plow and plant gardens': 'https://www.loc.gov/search/?fa=subject:plow+and+plant+gardens&fo=json'}, {'summer': 'https://www.loc.gov/search/?fa=subject:summer&fo=json'}]\n",
      "timestamp : 2022-03-29T07:30:17.382Z\n",
      "title : Bob Jarrell's vegetable garden\n",
      "type : ['photo, print, drawing']\n",
      "url : https://www.loc.gov/item/cmns001121/\n"
     ]
    }
   ],
   "source": [
    "# try first with one file, can you open the json, can you see what elements are in the json?\n",
    "with open(list_of_item_metadata_files[0], 'r', encoding='utf-8') as item:\n",
    "    # what are we looking at?\n",
    "    print('file:',list_of_item_metadata_files[0],'\\n')\n",
    "    \n",
    "    # load the item data\n",
    "    item_data = json.load(item)\n",
    "    \n",
    "    for element in item_data.keys():\n",
    "        print(element,':',item_data[element])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1b077",
   "metadata": {},
   "source": [
    "Look around in the dictionary a bit more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc1bdf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_version_', 'access_restricted', 'aka', 'call_number', 'campaigns', 'contributor_names', 'contributors', 'created_published', 'date', 'dates', 'digital_id', 'digitized', 'display_offsite', 'extract_timestamp', 'extract_urls', 'format', 'genre', 'group', 'hassegments', 'id', 'image_url', 'index', 'item', 'language', 'languages', 'location', 'locations', 'medium', 'mime_type', 'notes', 'online_format', 'original_format', 'other_formats', 'partof', 'repository', 'resources', 'rights', 'score', 'shard', 'shelf_id', 'source_collection', 'subject', 'subject_headings', 'subjects', 'timestamp', 'title', 'type', 'url'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49f8c4",
   "metadata": {},
   "source": [
    "For the development of your metadata transformation, you're looking for \n",
    "how to extract the elements identified in the MAP table. For example, which date fields do you want and where are they? Where will you find the format information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aecc7258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "date: 1996-06-28 <class 'str'>\n",
      "\n",
      "format: {'photo, print, drawing': 'https://www.loc.gov/search/?fa=original_format:photo,+print,+drawing&fo=json'} <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# can you get the date?\n",
    "print('\\ndate:',item_data['date'], type(item_data['date']))\n",
    "# can you get the format?\n",
    "print('\\nformat:',item_data['format'][0], type(item_data['format']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54be2cad-c5ef-4184-a2ea-3ae2da53db0f",
   "metadata": {},
   "source": [
    "## Test: Try it with one example\n",
    "\n",
    "First, try to set up the extract process with one example. This may get more complicated later since you don't know yet if every item has the same metadata attributes in the JSON. But start with some basics and build up from there. \n",
    "\n",
    "For a first pass, look out for these items, and find where in the JSON you can locate them:\n",
    "\n",
    "* 'item_id'\n",
    "* 'title'\n",
    "* 'date' \n",
    "* 'source_url'\n",
    "* 'phys_format'\n",
    "* 'dig_format'\n",
    "* 'rights'\n",
    "\n",
    "_Hint: use the JSON viewer in JupyterLab, use an extension in VSCode, or use a browser to look through sample JSON. The block below uses item `cph.3b41963`._\n",
    "\n",
    "You may need to use try/except patterns to create workarounds for cases where some items may not have exactly the same attributes that you've identified in your test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b20cbb86-d872-4e38-8673-0e4e6e2c06e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created row dictionary: {'source_file': 'item-metadata-gardens\\\\item_metadata-afc1999008.afc1999008_crf_mhc05407.json', 'item_id': 'cmns001121', 'title': \"Bob Jarrell's vegetable garden\", 'date': '1996-06-28', 'source_url': 'https://www.loc.gov/item/cmns001121/', 'phys_format': {'photo, print, drawing': 'https://www.loc.gov/search/?fa=original_format:photo,+print,+drawing&fo=json'}, 'dig_format': 'image', 'rights': 'Undetermined'}\n",
      "wrote collection_items_data_gardens.csv\n"
     ]
    }
   ],
   "source": [
    "# set up the containers to create the csv of all the item fields\n",
    "# file for csv to read out\n",
    "collection_info_csv = 'collection_items_data_gardens.csv'\n",
    "\n",
    "# set up a list for the columns in your csv; \n",
    "# your goal should be to automate this, but . . . \n",
    "# it works for demonstration as you set up the crosswalk\n",
    "headers = ['source_file', 'item_id', 'title', 'date', 'source_url', 'phys_format', 'dig_format', 'rights']\n",
    "\n",
    "# try first with one file\n",
    "with open(list_of_item_metadata_files[0], 'r', encoding='utf-8') as data:\n",
    "    # load the item data\n",
    "    item_data = json.load(data)\n",
    "    \n",
    "    # extract the data you want\n",
    "    # for checking purposes, add in the source of the info\n",
    "    source_file = str(list_of_item_metadata_files[0])\n",
    "    # make sure there's some unique and stable identifier\n",
    "    try:\n",
    "        item_id = item_data['library_of_congress_control_number']\n",
    "    except:\n",
    "        item_id = item_data['url'].split('/')[-2]\n",
    "        \n",
    "    title = item_data['title']\n",
    "    date = item_data['date']\n",
    "    source_url = item_data['url']\n",
    "    \n",
    "    try:\n",
    "        phys_format = item_data['format'][0]\n",
    "    except:\n",
    "        phys_format = 'Not found'\n",
    "        \n",
    "    try:\n",
    "        dig_format = item_data['online_format'][0]\n",
    "    except:\n",
    "        dig_format = 'Not found'\n",
    "        \n",
    "    mime_type = item_data['mime_type']\n",
    "    \n",
    "    try:\n",
    "        rights = item_data['rights_information']\n",
    "    except:\n",
    "        rights = 'Undetermined'\n",
    "\n",
    "\n",
    "    # dictionary for the rows\n",
    "    row_dict = dict()\n",
    "    \n",
    "    # look for the item metadata, assign it to the dictionary; \n",
    "    # start with some basic elements likely (already enumerated in the headers list) :\n",
    "    # source file\n",
    "    row_dict['source_file'] = source_file\n",
    "    # identifier\n",
    "    row_dict['item_id'] = item_id\n",
    "    # title\n",
    "    row_dict['title'] = title\n",
    "    # date\n",
    "    row_dict['date'] = date\n",
    "    # link\n",
    "    row_dict['source_url'] = source_url\n",
    "    # format\n",
    "    row_dict['phys_format'] = phys_format\n",
    "    # digital format\n",
    "    row_dict['dig_format'] = dig_format\n",
    "    #rights\n",
    "    row_dict['rights'] = rights \n",
    "    print('created row dictionary:',row_dict)\n",
    "\n",
    "    # write to the csv\n",
    "    with open(collection_info_csv, 'w', encoding='utf-8') as fout:\n",
    "        writer = csv.DictWriter(fout, fieldnames=headers, lineterminator='\\n')\n",
    "        writer.writeheader()\n",
    "        writer.writerow(row_dict)\n",
    "        print('wrote',collection_info_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db1d9c5-4ec4-45e2-b9a0-38ebdd6cb812",
   "metadata": {},
   "source": [
    "You're now developing the structure of the CSV file that will import items into your Omeka S site. The CSV import module supports the loading of item files via a URL. This provides the location of a file (in this case, an image), which Omeka will copy into its database and attach to your item. This means that it isn't necessary to upload individual files after or during metadata creation. \n",
    "\n",
    "To allow this, you need to find a direct url to a good image file for the item. There are multiple options, and the code below demonstrates looking for the url to a medium-sized image of an item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3b57056-6708-488f-a196-3a69f477cf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tile.loc.gov/image-services/iiif/service:afc:afc1999008:afc1999008_crf_mhc05407/full/pct:50/0/default.jpg#h=1388&w=2048\n"
     ]
    }
   ],
   "source": [
    "collection_info_csv = 'collection_items_data_gardens.csv'\n",
    "\n",
    "# set up a list for the columns in your csv; in future, this should be more automated but this works for now as you set up the crosswalk\n",
    "headers = ['source_file', 'item_id', 'title', 'date', 'source_url', 'phys_format', 'dig_format', 'rights']\n",
    "\n",
    "# try first with one file\n",
    "with open(list_of_item_metadata_files[0], 'r', encoding='utf-8') as data:\n",
    "    # load the item data\n",
    "    item_data = json.load(data)\n",
    "    \n",
    "    print(item_data['image_url'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec775d7-ab10-45c3-88ad-40706c100967",
   "metadata": {},
   "source": [
    "# Transformation Part 2: Write your CSV\n",
    "\n",
    "The goal of this final step is to create a CSV file, which will be possible to import into your Omeka site. It may seem like it's taken a long time to get to this point... but remember, when this works you will be importing around 60 items into the site at one time, so if you can get all of this to work for an even larger set of materials, you will be saving quite a lot of time in the future when you need to import items. Even if you were to collect the items piecemeal, which would need a different workflow than illustrated here, you can accomplish similar goals by recording metadata for each item consistently and in a spreadsheet, which you can then use to import the items in batch.\n",
    "\n",
    "So now that your transformation script is tested, the goal is to extend this to the whole set by looping through each of the desired JSON files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6546cb-d74c-46b7-8286-80df234878a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed collection_items_data_gardens.csv\n",
      "opening item-metadata-gardens\\item_metadata-afc1999008.afc1999008_crf_mhc05407.json\n",
      "adding cmns001121\n",
      "opening item-metadata-gardens\\item_metadata-cph.3a25266.json\n",
      "adding 2001703638\n",
      "opening item-metadata-gardens\\item_metadata-cph.3c30923.json\n",
      "adding 2017865756\n",
      "opening item-metadata-gardens\\item_metadata-cph.3f05737.json\n",
      "adding 99400959\n",
      "opening item-metadata-gardens\\item_metadata-cph.3g05158.json\n",
      "adding 97502889\n",
      "opening item-metadata-gardens\\item_metadata-ds.03659.json\n",
      "adding 2013645840\n",
      "opening item-metadata-gardens\\item_metadata-ds.13761.json\n",
      "adding 2020630497\n",
      "opening item-metadata-gardens\\item_metadata-fsa.8a19113.json\n",
      "adding 2017732863\n",
      "opening item-metadata-gardens\\item_metadata-fsa.8b14071.json\n",
      "adding 2017762632\n",
      "opening item-metadata-gardens\\item_metadata-fsa.8b14514.json\n",
      "adding 2017764422\n",
      "opening item-metadata-gardens\\item_metadata-fsa.8c19781.json\n",
      "adding 2017812834\n",
      "opening item-metadata-gardens\\item_metadata-fsa.8d21091.json\n",
      "adding 2017832184\n",
      "opening item-metadata-gardens\\item_metadata-fsa.8d31670.json\n",
      "adding 2017859523\n",
      "opening item-metadata-gardens\\item_metadata-ggbain.01389.json\n",
      "adding 2014681384\n",
      "opening item-metadata-gardens\\item_metadata-hhh.ca1376.photos.json\n",
      "adding ca1376\n",
      "opening item-metadata-gardens\\item_metadata-hhh.ma1202.sheet.json\n",
      "adding ma1202\n",
      "opening item-metadata-gardens\\item_metadata-highsm.13145.json\n",
      "adding 2011631339\n",
      "opening item-metadata-gardens\\item_metadata-highsm.16140.json\n",
      "adding 2011634333\n",
      "opening item-metadata-gardens\\item_metadata-highsm.17208.json\n",
      "adding 2011635401\n",
      "opening item-metadata-gardens\\item_metadata-highsm.18085.json\n",
      "adding 2011636279\n",
      "opening item-metadata-gardens\\item_metadata-highsm.51078.json\n",
      "adding 2018699280\n",
      "opening item-metadata-gardens\\item_metadata-highsm.58260.json\n",
      "adding 2019690684\n",
      "opening item-metadata-gardens\\item_metadata-mrg.00279.json\n",
      "adding 2017702393\n",
      "opening item-metadata-gardens\\item_metadata-npcc.20263.json\n",
      "adding 2016821817\n",
      "opening item-metadata-gardens\\item_metadata-pga.14314.json\n",
      "adding 2016652451\n",
      "opening item-metadata-gardens\\item_metadata-ppmsc.05210.json\n",
      "adding 2001698553\n",
      "opening item-metadata-gardens\\item_metadata-ppmsc.08589.json\n",
      "adding 2002696950\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.16143.json\n",
      "adding 2007685069\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.16211.json\n",
      "adding 2007685902\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.16216.json\n",
      "adding 2007685907\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.16226.json\n",
      "adding 2007685917\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.16693.json\n",
      "adding 2008675993\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.16752.json\n",
      "adding 2008676052\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.38775.json\n",
      "adding 2015647541\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.67920.json\n",
      "adding 2016653458\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.83823.json\n",
      "adding 2022654691\n",
      "opening item-metadata-gardens\\item_metadata-ppmsca.83865.json\n",
      "adding 2022654406\n",
      "opening item-metadata-gardens\\item_metadata-stereo.1s00324.json\n",
      "adding 2005694526\n",
      "opening item-metadata-gardens\\item_metadata-stereo.1s04657.json\n",
      "adding 2016646706\n",
      "opening item-metadata-gardens\\item_metadata-stereo.1s06147.json\n",
      "adding 2017648032\n",
      "opening item-metadata-gardens\\item_metadata-stereo.1s07844.json\n",
      "adding 2017659035\n",
      "opening item-metadata-gardens\\item_metadata-stereo.1s08717.json\n",
      "adding 2017651458\n",
      "opening item-metadata-gardens\\item_metadata-stereo.1s26666.json\n",
      "adding 2020681423\n",
      "opening item-metadata-gardens\\item_metadata-stereo.1s30968.json\n",
      "adding 2020634322\n",
      "opening item-metadata-gardens\\item_metadata-stereo.1s31930.json\n",
      "adding 2020637604\n",
      "opening item-metadata-gardens\\item_metadata-stereo.1s38444.json\n",
      "adding 2022645109\n",
      "opening item-metadata-gardens\\item_metadata-thc.5a50527.json\n",
      "adding 2019684989\n",
      "opening item-metadata-gardens\\item_metadata-wtc.4a03254.json\n",
      "adding 2004707960\n",
      "\n",
      "\n",
      "--- LOG ---\n",
      "wrote collection_items_data_gardens.csv\n",
      "with 48 items\n",
      "0 errors (info not written)\n"
     ]
    }
   ],
   "source": [
    "# for purposes of demonstration, use this block to make sure there isn't already a list file:\n",
    "\n",
    "items_data_file = os.path.join('collection_items_data_gardens.csv')\n",
    "\n",
    "if os.path.isfile(items_data_file):\n",
    "    os.unlink(items_data_file)\n",
    "    print('removed',items_data_file)\n",
    "\n",
    "# clear row_dict\n",
    "row_dict = {}\n",
    "\n",
    "# get date string for upload date\n",
    "from datetime import date\n",
    "date_string_for_today = date.today().strftime('%Y-%m-%d') # see https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\n",
    "\n",
    "# set up the containers to create the csv & counters\n",
    "# file for csv to read out\n",
    "collection_info_csv = os.path.join('collection_items_data_gardens.csv')\n",
    "file_count = 0\n",
    "items_written = 0\n",
    "error_count = 0\n",
    "\n",
    "# add in a couple of extras for Omeka, including item type and date uploaded\n",
    "\n",
    "# set up a list for the columns in your csv; in future, this should be more automated but this works for now as you set up the crosswalk\n",
    "headers = ['item_type', 'date_uploaded', 'source_file', 'item_id', 'title', 'date', 'source_url', 'phys_format', 'dig_format', 'rights', 'image_url',\n",
    "           'creators', 'description', 'subject_headings', 'source_collection', 'url', 'notes']\n",
    "\n",
    "# now, adapt the previous loop to open each file:\n",
    "for file in list_of_item_metadata_files:\n",
    "    file_count += 1\n",
    "    print('opening',file)\n",
    "    with open(file, 'r', encoding='utf-8') as item:\n",
    "        # load the item data\n",
    "        try:\n",
    "            item_data = json.load(item)\n",
    "        except:\n",
    "            print('error loading',file)\n",
    "            error_count += 1\n",
    "            continue\n",
    "\n",
    "        # extract/name the data you want\n",
    "        # item type\n",
    "        item_type = 'Item'\n",
    "        # date uplaoded\n",
    "        date_uploaded = date_string_for_today\n",
    "        # for checking purposes, add in the source of the info\n",
    "        source_file = str(file)\n",
    "        # make sure there's some unique and stable identifier\n",
    "        try:\n",
    "            item_id = item_data['library_of_congress_control_number']\n",
    "        except:\n",
    "            item_id = item_data['url'].split('/')[-2]\n",
    "            \n",
    "        title = item_data['title']\n",
    "        \n",
    "        try:\n",
    "            date = item_data['date']\n",
    "        except:\n",
    "            date = 'Not found'\n",
    "            \n",
    "        source_url = item_data['url']\n",
    "        \n",
    "        try:\n",
    "            phys_format = item_data['format'][0]\n",
    "        except:\n",
    "            phys_format = 'Not found'\n",
    "            \n",
    "        try:\n",
    "            dig_format = item_data['online_format'][0]\n",
    "        except:\n",
    "            dig_format = 'Not found'\n",
    "            \n",
    "        mime_type = item_data['mime_type']\n",
    "        \n",
    "        try:\n",
    "            rights = item_data['rights_information']\n",
    "        except:\n",
    "            rights = 'Undetermined'\n",
    "        \n",
    "        try:\n",
    "            image_url = item_data['image_url'][-1]\n",
    "        except:\n",
    "            image_url = 'Did not identify a URL.'\n",
    "        \n",
    "        try:\n",
    "            creators = item_data['item']['contributors']\n",
    "        except:\n",
    "            try:\n",
    "                creators = []\n",
    "                for contributor in item_data['contributors']:\n",
    "                    creators.extend(contributor.keys())\n",
    "            except:\n",
    "                creators = []\n",
    "\n",
    "        try:\n",
    "            description = item_data['summary']\n",
    "        except:\n",
    "            description = 'Not found'\n",
    "        \n",
    "        try:\n",
    "            subject_headings = item_data['subject_headings']\n",
    "        except:\n",
    "            subject_headings = []\n",
    "        \n",
    "        try:\n",
    "            source_collection = item_data['source_collection']\n",
    "        except:\n",
    "            source_collection = 'Not found'\n",
    "        \n",
    "        try:\n",
    "            url = item_data['link']\n",
    "        except:\n",
    "            url = 'Not found'\n",
    "        \n",
    "        try:\n",
    "            notes = item_data['notes']\n",
    "        except:\n",
    "            notes = []\n",
    "        \n",
    "        # dictionary for the rows\n",
    "        row_dict = dict()\n",
    "\n",
    "        # look for the item metadata, assign it to the dictionary; \n",
    "        # start with some basic elements likely (already enumerated in the headers list) :\n",
    "        # item type\n",
    "        row_dict['item_type'] = item_type\n",
    "        # date uploaded\n",
    "        row_dict['date_uploaded'] = date_uploaded\n",
    "        # source filename\n",
    "        row_dict['source_file'] = source_file\n",
    "        # identifier\n",
    "        row_dict['item_id'] = item_id\n",
    "        # title\n",
    "        row_dict['title'] = title\n",
    "        # date\n",
    "        row_dict['date'] = date\n",
    "        # link\n",
    "        row_dict['source_url'] = source_url\n",
    "        # format\n",
    "        row_dict['phys_format'] = phys_format\n",
    "        # digital format\n",
    "        row_dict['dig_format'] = dig_format.capitalize()\n",
    "        # rights\n",
    "        row_dict['rights'] = rights\n",
    "        # image\n",
    "        row_dict['image_url'] = image_url\n",
    "        # creators\n",
    "        row_dict['creators'] = creators\n",
    "        # description\n",
    "        row_dict['description'] = description\n",
    "        # subject headings\n",
    "        row_dict['subject_headings'] = subject_headings\n",
    "        # source collection\n",
    "        row_dict['source_collection'] = source_collection\n",
    "        # url\n",
    "        row_dict['url'] = url\n",
    "        # notes\n",
    "        row_dict['notes'] = notes\n",
    "\n",
    "        # write to the csv\n",
    "        with open(collection_info_csv, 'a', encoding='utf-8') as fout:\n",
    "            writer = csv.DictWriter(fout, fieldnames=headers, lineterminator='\\n')\n",
    "            if items_written == 0:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(row_dict)\n",
    "            items_written += 1\n",
    "            print('adding',item_id)\n",
    "\n",
    "print('\\n\\n--- LOG ---')\n",
    "print('wrote',collection_info_csv)\n",
    "print('with',items_written,'items')\n",
    "print(error_count,'errors (info not written)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61260c5d-0bfd-4dc4-8c1f-e113b75b9fce",
   "metadata": {},
   "source": [
    "Now, you should have a well-formed, complete CSV file at `data/collection_items_data.csv`. This file should have all the information to import the 59 items that you were able to identify. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
